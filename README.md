# Lightweight American Sign Language and Gesture Recognition Using YOLOv8.

## Introduction

Many people who cannot hear or speak use hand signs called American Sign Language (ASL) to communicate. But not everyone understands these signs, which can make talking to others hard.

This project helps solve that problem by creating a system that can **see hand signs** in real time using a camera, and then **convert those signs into words and speech**. This way, people who don’t know sign language can understand what someone is trying to say.

---

## How It Works

1. The system uses a camera (like your laptop’s webcam) to watch hand movements.
2. It finds the hand in the video and looks closely at the shape and position of the fingers.
3. It matches the hand signs to the letters or words they represent in ASL.
4. It shows the recognized words on the screen and can also speak them out loud.

---

## Technology Used

* **YOLOv8:** A smart program that quickly finds hands in video images.
* **Deep Learning:** A type of artificial intelligence that learns to recognize different hand signs by studying many examples.
* **Speech Output:** Converts the recognized signs into spoken words.
* **Python:** The main programming language used to build the system.

---

## Dataset

The system learned to recognize signs by studying thousands of images showing different hand gestures of the ASL alphabet. This helps the program understand signs in many different lighting and backgrounds.

---

## Benefits

* Helps people who use sign language talk with others who don’t understand it.
* Makes communication easier and faster.
* Can be used for learning and teaching sign language.
* Works in real time, so conversations feel natural.

